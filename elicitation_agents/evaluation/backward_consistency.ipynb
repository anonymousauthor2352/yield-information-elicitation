{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ed6d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Imports ----------------\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f256f755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Config ----------------\n",
    "with open(\"../../config/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "data_path = config[\"paths\"][\"proj_store\"]\n",
    "models_folderpath = config[\"paths\"][\"models\"]\n",
    "\n",
    "generated_blocks_file = \"2025_09_01_15_46_09_llama_3_8b_instruct_generated_blocks\"\n",
    "\n",
    "model_choice = f\"{models_folderpath}/sentence-transformers/all-MiniLM-L12-v2\"\n",
    "domain_index_file = f\"{data_path}/indexes/domain_index_by_id.json\"\n",
    "\n",
    "# --- configuration---\n",
    "merged_jsonl_path = f\"{data_path}/output/generated_blocks/{generated_blocks_file}.jsonl\"\n",
    "results_root = f\"{data_path}/results/interaction_metrics/generated_dataset\"\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# MODEL INIT\n",
    "# ------------------------\n",
    "# Load sentence embedding model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "embedding_model = SentenceTransformer(model_choice, device=device)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51acb9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Load JSONL\n",
    "# ------------------------\n",
    "def load_merged_jsonl(path: str):\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f, 1):\n",
    "            s = line.strip()\n",
    "            if not s:\n",
    "                continue\n",
    "            obj = json.loads(s)\n",
    "            assert \"block_id\" in obj and \"context_turns\" in obj and \"response_turns\" in obj, f\"{path}:{i} missing keys\"\n",
    "            rows.append(obj)\n",
    "    return rows\n",
    "\n",
    "\n",
    "def sequence_from_record(rec: dict, resp_label: str):\n",
    "    # take turns 1..4 from context_turns\n",
    "    ctx = sorted(rec[\"context_turns\"], key=lambda x: x.get(\"turn\", 0))[:4]\n",
    "    # get response (turn 5)\n",
    "    resp = next((r for r in rec[\"response_turns\"] if r.get(\"label\") == resp_label), None)\n",
    "    if resp is None:\n",
    "        return None\n",
    "\n",
    "    turns = []\n",
    "    for t in ctx:\n",
    "        turns.append({\n",
    "            \"turn\": t.get(\"turn\"),\n",
    "            \"role\": t.get(\"role\", \"\").lower(),\n",
    "            \"label\": t.get(\"label\", \"real\"),\n",
    "            \"utterance\": t.get(\"utterance\", \"\").strip()\n",
    "        })\n",
    "    turns.append({\n",
    "        \"turn\": 5,\n",
    "        \"role\": resp.get(\"role\", \"\").lower(),\n",
    "        \"label\": resp_label,\n",
    "        \"utterance\": resp.get(\"utterance\", \"\").strip()\n",
    "    })\n",
    "\n",
    "    turns = sorted(turns, key=lambda x: x[\"turn\"])\n",
    "    if [t[\"turn\"] for t in turns] != [1, 2, 3, 4, 5]:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"block_id\": rec[\"block_id\"],\n",
    "        \"turns\": turns\n",
    "    }\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Load Domain Mapping\n",
    "# ------------------------\n",
    "with open(domain_index_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    _raw_domain_ix = json.load(f)\n",
    "\n",
    "dialogueid_to_domain = {row[\"dialogue_id\"]: row[\"domain\"] for row in _raw_domain_ix}\n",
    "\n",
    "def get_domain_from_block(block_id: str) -> str:\n",
    "    # block_id looks like \"jsc-oral-history-00128:23\"\n",
    "    dialogue_id = block_id.split(\":\")[0]\n",
    "    return dialogueid_to_domain.get(dialogue_id, \"Unknown\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "597da665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    \"\"\"Safe KL divergence with small epsilon to avoid log(0).\"\"\"\n",
    "    eps = 1e-10\n",
    "    p = np.asarray(p) + eps\n",
    "    q = np.asarray(q) + eps\n",
    "    p = p / p.sum()\n",
    "    q = q / q.sum()\n",
    "    return entropy(p, q)  # KL(P || Q)\n",
    "\n",
    "def js_divergence(p, q):\n",
    "    \"\"\"Symmetric Jensen–Shannon divergence.\"\"\"\n",
    "    m = 0.5 * (p + q)\n",
    "    return 0.5 * (kl_divergence(p, m) + kl_divergence(q, m))\n",
    "\n",
    "\n",
    "\n",
    "def compute_distribution_kl(df, metrics, labels, out_dir, timestamp, domain):\n",
    "    results = []\n",
    "    # build histograms on common bins per metric\n",
    "    for metric in metrics:\n",
    "        all_vals = df[metric].dropna().values\n",
    "        if len(all_vals) == 0:\n",
    "            continue\n",
    "        bins = np.linspace(all_vals.min(), all_vals.max(), 30)\n",
    "\n",
    "        # histograms per label\n",
    "        hists = {}\n",
    "        for lab in labels:\n",
    "            vals = df[df[\"Label\"] == lab][metric].dropna().values\n",
    "            if len(vals) == 0:\n",
    "                continue\n",
    "            hist, _ = np.histogram(vals, bins=bins, density=True)\n",
    "            hists[lab] = hist\n",
    "\n",
    "        # pairwise KL\n",
    "        lab_pairs = [(\"real\", \"fine_tuned\"), (\"real\", \"prompted\"), (\"fine_tuned\", \"prompted\")]\n",
    "        for a, b in lab_pairs:\n",
    "            if a in hists and b in hists:\n",
    "                kl_ab = kl_divergence(hists[a], hists[b])\n",
    "                kl_ba = kl_divergence(hists[b], hists[a])\n",
    "                results.append({\n",
    "                    \"Domain\": domain,\n",
    "                    \"Metric\": metric,\n",
    "                    \"KL_{}_to_{}\".format(a, b): kl_ab,\n",
    "                    \"KL_{}_to_{}\".format(b, a): kl_ba\n",
    "                })\n",
    "\n",
    "    if results:\n",
    "        out_df = pd.DataFrame(results)\n",
    "        out_csv = f\"{out_dir}/{timestamp}_kl_divergence_{domain}.csv\"\n",
    "        out_df.to_csv(out_csv, index=False)\n",
    "        print(f\"[info] wrote KL divergence results for domain={domain} to {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7693df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] built 28071 sequences from 9357 blocks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Response-Context Similarity:   0%|          | 1/28071 [00:00<1:00:05,  7.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Response-Context Similarity: 100%|██████████| 28071/28071 [04:17<00:00, 109.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] wrote raw similarities to /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_response_context_similarity.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------\n",
    "# Main\n",
    "# ------------------------\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "out_dir = f\"{results_root}/response_context_similarity\"\n",
    "Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "rows = load_merged_jsonl(merged_jsonl_path)\n",
    "seqs = []\n",
    "labels = [\"real\", \"fine_tuned\", \"prompted\"]\n",
    "for rec in rows:\n",
    "    for lab in labels:\n",
    "        s = sequence_from_record(rec, lab)\n",
    "        if s is not None:\n",
    "            s[\"domain\"] = get_domain_from_block(s[\"block_id\"])\n",
    "            seqs.append(s)\n",
    "print(f\"[info] built {len(seqs)} sequences from {len(rows)} blocks\")\n",
    "\n",
    "# Compute similarities\n",
    "similarity_records = []\n",
    "for dialogue in tqdm(seqs, desc=\"Response-Context Similarity\"):\n",
    "    turns = dialogue[\"turns\"]\n",
    "    context_utts = [t[\"utterance\"] for t in turns[:4]]\n",
    "    resp_utt = turns[4][\"utterance\"]\n",
    "\n",
    "    if not resp_utt.strip():\n",
    "        continue\n",
    "\n",
    "    embeddings = embedding_model.encode(context_utts + [resp_utt],\n",
    "                                        batch_size=32, show_progress_bar=False, device=device)\n",
    "    context_embs = embeddings[:4]\n",
    "    resp_emb = embeddings[4]\n",
    "\n",
    "    sims = [cosine_similarity([resp_emb], [ctx])[0][0] for ctx in context_embs]\n",
    "\n",
    "    similarity_records.append({\n",
    "        \"BlockID\": dialogue[\"block_id\"],\n",
    "        \"Domain\": dialogue[\"domain\"],\n",
    "        \"Label\": dialogue[\"turns\"][-1][\"label\"],\n",
    "        \"Sim_Turn_4\": sims[3],\n",
    "        \"Sim_Turn_3\": sims[2],\n",
    "        \"Sim_Turn_2\": sims[1],\n",
    "        \"Sim_Turn_1\": sims[0],\n",
    "        \"Sim_All_Avg\": float(np.mean(sims))\n",
    "    })\n",
    "\n",
    "# Save raw dataframe\n",
    "similarity_df = pd.DataFrame(similarity_records)\n",
    "csv_out = f\"{out_dir}/{timestamp}_response_context_similarity.csv\"\n",
    "similarity_df.to_csv(csv_out, index=False)\n",
    "print(f\"[info] wrote raw similarities to {csv_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5a1a9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] wrote summary averages for domain=oral_history to /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_response_context_similarity_summary_oral_history.csv\n",
      "[info] wrote summary averages for domain=academic_interviews to /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_response_context_similarity_summary_academic_interviews.csv\n",
      "[info] wrote summary averages for domain=judicial_dialogue to /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_response_context_similarity_summary_judicial_dialogue.csv\n",
      "[info] wrote summary averages for domain=journalistic_interviews to /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_response_context_similarity_summary_journalistic_interviews.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate per-domain summary tables\n",
    "domains = similarity_df[\"Domain\"].unique()\n",
    "for dom in domains:\n",
    "    subset = similarity_df[similarity_df[\"Domain\"] == dom]\n",
    "    if subset.empty:\n",
    "        continue\n",
    "\n",
    "    summary_rows = []\n",
    "    for label in labels:\n",
    "        lab_subset = subset[subset[\"Label\"] == label]\n",
    "        if lab_subset.empty:\n",
    "            continue\n",
    "        summary_rows.append({\n",
    "            \"Label\": label,\n",
    "            \"avg_sim_turn_4\": lab_subset[\"Sim_Turn_4\"].mean(),\n",
    "            \"avg_sim_turn_3\": lab_subset[\"Sim_Turn_3\"].mean(),\n",
    "            \"avg_sim_turn_2\": lab_subset[\"Sim_Turn_2\"].mean(),\n",
    "            \"avg_sim_turn_1\": lab_subset[\"Sim_Turn_1\"].mean(),\n",
    "            \"avg_sim_turn_all\": lab_subset[\"Sim_All_Avg\"].mean()\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    summary_csv_out = f\"{out_dir}/{timestamp}_response_context_similarity_summary_{dom}.csv\"\n",
    "    summary_df.to_csv(summary_csv_out, index=False)\n",
    "    print(f\"[info] wrote summary averages for domain={dom} to {summary_csv_out}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26d742be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_oral_history_real.png\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_oral_history_fine_tuned.png\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_oral_history_prompted.png\n",
      "[info] wrote summary averages for domain=oral_history to /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_response_context_similarity_summary_oral_history.csv\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_academic_interviews_real.png\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_academic_interviews_fine_tuned.png\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_academic_interviews_prompted.png\n",
      "[info] wrote summary averages for domain=academic_interviews to /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_response_context_similarity_summary_academic_interviews.csv\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_judicial_dialogue_real.png\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_judicial_dialogue_fine_tuned.png\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_judicial_dialogue_prompted.png\n",
      "[info] wrote summary averages for domain=judicial_dialogue to /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_response_context_similarity_summary_judicial_dialogue.csv\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_journalistic_interviews_real.png\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_journalistic_interviews_fine_tuned.png\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_journalistic_interviews_prompted.png\n",
      "[info] wrote summary averages for domain=journalistic_interviews to /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_response_context_similarity_summary_journalistic_interviews.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Per-domain summaries and plots\n",
    "domains = similarity_df[\"Domain\"].unique()\n",
    "for dom in domains:\n",
    "    subset = similarity_df[similarity_df[\"Domain\"] == dom]\n",
    "    if subset.empty:\n",
    "        continue\n",
    "\n",
    "    summary_rows = []\n",
    "    for label in labels:\n",
    "        lab_subset = subset[subset[\"Label\"] == label]\n",
    "        if lab_subset.empty:\n",
    "            continue\n",
    "        summary_rows.append({\n",
    "            \"Label\": label,\n",
    "            \"avg_sim_turn_4\": lab_subset[\"Sim_Turn_4\"].mean(),\n",
    "            \"avg_sim_turn_3\": lab_subset[\"Sim_Turn_3\"].mean(),\n",
    "            \"avg_sim_turn_2\": lab_subset[\"Sim_Turn_2\"].mean(),\n",
    "            \"avg_sim_turn_1\": lab_subset[\"Sim_Turn_1\"].mean(),\n",
    "            \"avg_sim_turn_all\": lab_subset[\"Sim_All_Avg\"].mean()\n",
    "        })\n",
    "\n",
    "        # Plot distributions for this domain × label\n",
    "        fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "        metrics = [\"Sim_Turn_4\", \"Sim_Turn_3\", \"Sim_Turn_2\", \"Sim_Turn_1\", \"Sim_All_Avg\"]\n",
    "        for ax, metric in zip(axes, metrics):\n",
    "            ax.hist(lab_subset[metric], bins=20, alpha=0.7)\n",
    "            ax.set_title(f\"{metric} ({label})\")\n",
    "            ax.set_xlabel(\"cosine similarity\")\n",
    "            ax.set_ylabel(\"count\")\n",
    "        plt.tight_layout()\n",
    "        plot_out = f\"{out_dir}/{timestamp}_distribution_{dom}_{label}.png\"\n",
    "        plt.savefig(plot_out)\n",
    "        plt.close()\n",
    "        print(f\"[info] wrote distribution plot {plot_out}\")\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    summary_csv_out = f\"{out_dir}/{timestamp}_response_context_similarity_summary_{dom}.csv\"\n",
    "    summary_df.to_csv(summary_csv_out, index=False)\n",
    "    print(f\"[info] wrote summary averages for domain={dom} to {summary_csv_out}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e0c967e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_oral_history_real.png\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_oral_history_fine_tuned.png\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_oral_history_prompted.png\n",
      "[info] wrote summary averages for domain=oral_history to /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_response_context_similarity_summary_oral_history.csv\n",
      "[info] wrote divergence analysis for domain=oral_history to /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_divergence_oral_history.csv\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_academic_interviews_real.png\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_academic_interviews_fine_tuned.png\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_academic_interviews_prompted.png\n",
      "[info] wrote summary averages for domain=academic_interviews to /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_response_context_similarity_summary_academic_interviews.csv\n",
      "[info] wrote divergence analysis for domain=academic_interviews to /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_divergence_academic_interviews.csv\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_judicial_dialogue_real.png\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_judicial_dialogue_fine_tuned.png\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_judicial_dialogue_prompted.png\n",
      "[info] wrote summary averages for domain=judicial_dialogue to /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_response_context_similarity_summary_judicial_dialogue.csv\n",
      "[info] wrote divergence analysis for domain=judicial_dialogue to /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_divergence_judicial_dialogue.csv\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_journalistic_interviews_real.png\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_journalistic_interviews_fine_tuned.png\n",
      "[info] wrote distribution plot /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_journalistic_interviews_prompted.png\n",
      "[info] wrote summary averages for domain=journalistic_interviews to /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_response_context_similarity_summary_journalistic_interviews.csv\n",
      "[info] wrote divergence analysis for domain=journalistic_interviews to /data/sequential_ieas//results/interaction_metrics/generated_dataset/response_context_similarity/2025_09_22_22_09_05_distribution_divergence_journalistic_interviews.csv\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    \"\"\"Safe KL divergence with small epsilon to avoid log(0).\"\"\"\n",
    "    eps = 1e-10\n",
    "    p = np.asarray(p) + eps\n",
    "    q = np.asarray(q) + eps\n",
    "    p = p / p.sum()\n",
    "    q = q / q.sum()\n",
    "    return entropy(p, q)  # KL(P || Q)\n",
    "\n",
    "def js_divergence(p, q):\n",
    "    \"\"\"Symmetric Jensen–Shannon divergence.\"\"\"\n",
    "    m = 0.5 * (p + q)\n",
    "    return 0.5 * (kl_divergence(p, m) + kl_divergence(q, m))\n",
    "\n",
    "\n",
    "# Per-domain summaries, plots, and divergences\n",
    "domains = similarity_df[\"Domain\"].unique()\n",
    "for dom in domains:\n",
    "    subset = similarity_df[similarity_df[\"Domain\"] == dom]\n",
    "    if subset.empty:\n",
    "        continue\n",
    "\n",
    "    summary_rows = []\n",
    "    for label in labels:\n",
    "        lab_subset = subset[subset[\"Label\"] == label]\n",
    "        if lab_subset.empty:\n",
    "            continue\n",
    "        summary_rows.append({\n",
    "            \"Label\": label,\n",
    "            \"avg_sim_turn_4\": lab_subset[\"Sim_Turn_4\"].mean(),\n",
    "            \"avg_sim_turn_3\": lab_subset[\"Sim_Turn_3\"].mean(),\n",
    "            \"avg_sim_turn_2\": lab_subset[\"Sim_Turn_2\"].mean(),\n",
    "            \"avg_sim_turn_1\": lab_subset[\"Sim_Turn_1\"].mean(),\n",
    "            \"avg_sim_turn_all\": lab_subset[\"Sim_All_Avg\"].mean()\n",
    "        })\n",
    "\n",
    "        # Plot distributions for this domain × label\n",
    "        fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "        metrics = [\"Sim_Turn_4\", \"Sim_Turn_3\", \"Sim_Turn_2\", \"Sim_Turn_1\", \"Sim_All_Avg\"]\n",
    "        for ax, metric in zip(axes, metrics):\n",
    "            ax.hist(lab_subset[metric], bins=20, alpha=0.7)\n",
    "            ax.set_title(f\"{metric} ({label})\")\n",
    "            ax.set_xlabel(\"cosine similarity\")\n",
    "            ax.set_ylabel(\"count\")\n",
    "        plt.tight_layout()\n",
    "        plot_out = f\"{out_dir}/{timestamp}_distribution_{dom}_{label}.png\"\n",
    "        plt.savefig(plot_out)\n",
    "        plt.close()\n",
    "        print(f\"[info] wrote distribution plot {plot_out}\")\n",
    "\n",
    "    # Save summary averages\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    summary_csv_out = f\"{out_dir}/{timestamp}_response_context_similarity_summary_{dom}.csv\"\n",
    "    summary_df.to_csv(summary_csv_out, index=False)\n",
    "    print(f\"[info] wrote summary averages for domain={dom} to {summary_csv_out}\")\n",
    "\n",
    "    # ---- Divergence analysis ----\n",
    "    metrics = [\"Sim_Turn_4\", \"Sim_Turn_3\", \"Sim_Turn_2\", \"Sim_Turn_1\", \"Sim_All_Avg\"]\n",
    "    label_pairs = [(\"real\", \"fine_tuned\"), (\"real\", \"prompted\"), (\"fine_tuned\", \"prompted\")]\n",
    "    div_results = []\n",
    "\n",
    "    for metric in metrics:\n",
    "        # Build bins for this metric (common to all labels in domain)\n",
    "        all_vals = subset[metric].dropna().values\n",
    "        if len(all_vals) == 0:\n",
    "            continue\n",
    "        bins = np.linspace(all_vals.min(), all_vals.max(), 30)\n",
    "\n",
    "        # Histograms per label\n",
    "        hists = {}\n",
    "        for lab in labels:\n",
    "            vals = subset[subset[\"Label\"] == lab][metric].dropna().values\n",
    "            if len(vals) == 0:\n",
    "                continue\n",
    "            hist, _ = np.histogram(vals, bins=bins, density=True)\n",
    "            hists[lab] = hist\n",
    "\n",
    "        # Pairwise divergences\n",
    "        for a, b in label_pairs:\n",
    "            if a in hists and b in hists:\n",
    "                p, q = hists[a], hists[b]\n",
    "                div_results.append({\n",
    "                    \"Domain\": dom,\n",
    "                    \"Metric\": metric,\n",
    "                    \"Pair\": f\"{a}_vs_{b}\",\n",
    "                    \"KL_a_to_b\": kl_divergence(p, q),\n",
    "                    \"KL_b_to_a\": kl_divergence(q, p),\n",
    "                    \"JSD\": js_divergence(p, q)\n",
    "                })\n",
    "\n",
    "    if div_results:\n",
    "        div_df = pd.DataFrame(div_results)\n",
    "        div_csv_out = f\"{out_dir}/{timestamp}_distribution_divergence_{dom}.csv\"\n",
    "        div_df.to_csv(div_csv_out, index=False)\n",
    "        print(f\"[info] wrote divergence analysis for domain={dom} to {div_csv_out}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sequential_ieas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
