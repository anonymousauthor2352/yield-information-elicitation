{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0ff4fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Imports ----------------\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "963494f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Args ----------------\n",
    "prompted_input_file_name = \"20251219T1217-llama-3.1-8b-instruct-pr-m3generated\"\n",
    "sft_input_file_name = \"20251221T0934-20251220t0857-llama-3.1-8b-instruct-sft-m3trained\"\n",
    "orl_input_file_name = \"20251227T0854-20251226t0940-llama-3.1-8b-instruct-seq-std-m3trained\"\n",
    "\n",
    "random_state_seed = 42\n",
    "sample_size = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "134b0074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Config ----------------\n",
    "with open(\"../../../config/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "random.seed(random_state_seed)\n",
    "\n",
    "\n",
    "proj_store = config[\"paths\"][\"proj_store\"]\n",
    "models_folderpath = config[\"paths\"][\"models\"]\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%dt%H%M%S\")\n",
    "\n",
    "utterances_dir = os.path.join(proj_store, \"evaluation\", \"generated-utterances\")\n",
    "\n",
    "prompted_input_file = os.path.join(utterances_dir, f\"{prompted_input_file_name}.jsonl\")\n",
    "sft_input_file = os.path.join(utterances_dir, f\"{sft_input_file_name}.jsonl\")\n",
    "orl_input_file = os.path.join(utterances_dir, f\"{orl_input_file_name}.jsonl\")\n",
    "\n",
    "\n",
    "human_eval_folder = os.path.join(proj_store, \"evaluation\", \"human-evaluation\")\n",
    "os.makedirs(human_eval_folder, exist_ok=True)\n",
    "\n",
    "combined_input_folder = os.path.join(human_eval_folder, \"combined-utterances\")\n",
    "os.makedirs(combined_input_folder, exist_ok=True)\n",
    "combined_input_file = os.path.join(combined_input_folder, f\"{timestamp}-combined-utterances.jsonl\")\n",
    "\n",
    "output_file_dir = os.path.join(human_eval_folder, \"batches\")\n",
    "os.makedirs(output_file_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_file_dir, f\"{timestamp}-batch.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "60d9c0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl_with_order(path):\n",
    "    ordered = []\n",
    "    lookup = {}\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line_idx, line in enumerate(f):\n",
    "            obj = json.loads(line)\n",
    "            block_id = obj.get(\"block_id\")\n",
    "\n",
    "            if block_id is None:\n",
    "                raise ValueError(f\"Missing block_id in file {path} at line {line_idx}\")\n",
    "\n",
    "            if block_id in lookup:\n",
    "                raise ValueError(f\"Duplicate block_id {block_id} in file {path}\")\n",
    "\n",
    "            ordered.append(obj)\n",
    "            lookup[block_id] = obj\n",
    "\n",
    "    return ordered, lookup\n",
    "\n",
    "\n",
    "\n",
    "prompted_ordered, prompted_lookup = read_jsonl_with_order(prompted_input_file)\n",
    "_, sft_lookup = read_jsonl_with_order(sft_input_file)\n",
    "_, orl_lookup = read_jsonl_with_order(orl_input_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "373cda56",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompted_ids = set(prompted_lookup.keys())\n",
    "sft_ids = set(sft_lookup.keys())\n",
    "orl_ids = set(orl_lookup.keys())\n",
    "\n",
    "if not (prompted_ids == sft_ids == orl_ids):\n",
    "    raise RuntimeError(\n",
    "        \"Block ID mismatch detected:\\n\"\n",
    "        f\"- Missing in SFT: {sorted(prompted_ids - sft_ids)}\\n\"\n",
    "        f\"- Missing in ORL: {sorted(prompted_ids - orl_ids)}\\n\"\n",
    "        f\"- Missing in Prompted: {sorted((sft_ids | orl_ids) - prompted_ids)}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b725c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_records = []\n",
    "\n",
    "for base in prompted_ordered:\n",
    "    block_id = base[\"block_id\"]\n",
    "\n",
    "    record = base.copy()\n",
    "\n",
    "    if \"context_messages\" in record:\n",
    "        record[\"context_messages\"] = [\n",
    "            msg for msg in record[\"context_messages\"]\n",
    "            if msg.get(\"role\") != \"system\"\n",
    "        ]\n",
    "\n",
    "    # Rename prompted generated_response\n",
    "    if \"generated_response\" not in record:\n",
    "        raise ValueError(f\"Missing generated_response in prompted for block_id={block_id}\")\n",
    "\n",
    "    record[\"generated_response_prompted\"] = record.pop(\"generated_response\")\n",
    "\n",
    "    # Add others\n",
    "    record[\"generated_response_sft\"] = sft_lookup[block_id].get(\"generated_response\")\n",
    "    record[\"generated_response_orl\"] = orl_lookup[block_id].get(\"generated_response\")\n",
    "\n",
    "    if record[\"generated_response_sft\"] is None:\n",
    "        raise ValueError(f\"Missing generated_response in sft for block_id={block_id}\")\n",
    "    if record[\"generated_response_orl\"] is None:\n",
    "        raise ValueError(f\"Missing generated_response in orl for block_id={block_id}\")\n",
    "\n",
    "    combined_records.append(record)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b554e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(combined_input_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for rec in combined_records:\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e2a5b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Load combined file ----------------\n",
    "rows = []\n",
    "\n",
    "with open(combined_input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "\n",
    "        block_id = item[\"block_id\"]\n",
    "        if \"domain\" not in item or item[\"domain\"] is None:\n",
    "            raise ValueError(f\"Missing domain for block_id={item['block_id']}\")\n",
    "        domain = item[\"domain\"]\n",
    "\n",
    "        # ---------------- Format context into HTML ----------------\n",
    "        ROLE_MAP = {\n",
    "            \"user\": \"Respondent\",\n",
    "            \"assistant\": \"Elicitor\",\n",
    "        }\n",
    "\n",
    "        context_lines = []\n",
    "        for turn in item[\"context_messages\"]:\n",
    "            raw_role = turn[\"role\"]\n",
    "            role = ROLE_MAP.get(raw_role, raw_role.capitalize())\n",
    "            utterance = turn[\"content\"]\n",
    "            context_lines.append(f\"<li><b>{role}</b>: {utterance}</li>\")\n",
    "\n",
    "        context_str = \"<ul>\\n\" + \"\\n\".join(context_lines) + \"\\n</ul>\"\n",
    "\n",
    "        # ---------------- Collect responses ----------------\n",
    "        if \"real_response\" not in item or item[\"real_response\"] is None:\n",
    "            raise ValueError(f\"Missing real_response for block_id={block_id}\")\n",
    "\n",
    "        responses = [\n",
    "            (\"real\", item[\"real_response\"]),\n",
    "            (\"prompted\", item[\"generated_response_prompted\"]),\n",
    "            (\"sft\", item[\"generated_response_sft\"]),\n",
    "            (\"orl\", item[\"generated_response_orl\"]),\n",
    "        ]\n",
    "\n",
    "        # Shuffle responses (evaluation blindness)\n",
    "        random.shuffle(responses)\n",
    "\n",
    "        # ---------------- Build row ----------------\n",
    "        row = {\n",
    "            \"block_id\": block_id,\n",
    "            #\"type\": \"evaluation\",\n",
    "            \"domain\": domain,\n",
    "            \"context_turns\": context_str,\n",
    "        }\n",
    "\n",
    "        for i, (label, utt) in enumerate(responses, start=1):\n",
    "            row[f\"response_{i}\"] = f\"<b>Elicitor</b>: {utt}\"\n",
    "            row[f\"response_{i}_label\"] = label\n",
    "\n",
    "        rows.append(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "97c32e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "domain\n",
       "judicial_proceedings           4949\n",
       "oral_history                   4028\n",
       "academic_interviews            1125\n",
       "journalistic_investigations     183\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create DataFrame\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "df[\"domain\"].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "634459ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stratified sampling\n",
    "\n",
    "n_domains = df[\"domain\"].nunique()\n",
    "sample_per_domain = sample_size // n_domains\n",
    "\n",
    "df_sampled = (\n",
    "    df.groupby(\"domain\", group_keys=False, sort=False)\n",
    "      .sample(n=sample_per_domain, random_state=random_state_seed)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Domain normalization\n",
    "\n",
    "df[\"domain\"] = df[\"domain\"].str.replace(\"_\", \" \").str.title()\n",
    "df_sampled[\"domain\"] = df_sampled[\"domain\"].str.replace(\"_\", \" \").str.title()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8aa6b37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_id</th>\n",
       "      <th>domain</th>\n",
       "      <th>context_turns</th>\n",
       "      <th>response_1</th>\n",
       "      <th>response_1_label</th>\n",
       "      <th>response_2</th>\n",
       "      <th>response_2_label</th>\n",
       "      <th>response_3</th>\n",
       "      <th>response_3_label</th>\n",
       "      <th>response_4</th>\n",
       "      <th>response_4_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wikinews-00000:38</td>\n",
       "      <td>Journalistic Investigations</td>\n",
       "      <td>&lt;ul&gt;\\n&lt;li&gt;&lt;b&gt;Respondent&lt;/b&gt;: I have very littl...</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: It looks very painful, your l...</td>\n",
       "      <td>real</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: It sounds like you've had a l...</td>\n",
       "      <td>prompted</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: Can you walk at all?</td>\n",
       "      <td>sft</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: You mentioned your vision. Do...</td>\n",
       "      <td>orl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wikinews-00000:84</td>\n",
       "      <td>Journalistic Investigations</td>\n",
       "      <td>&lt;ul&gt;\\n&lt;li&gt;&lt;b&gt;Respondent&lt;/b&gt;: Yes there is. Sug...</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: What about MySpace and YouTub...</td>\n",
       "      <td>orl</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: So it sounds like you're real...</td>\n",
       "      <td>prompted</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: Is your goal to raise money o...</td>\n",
       "      <td>sft</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: Why do you think there are so...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>voa-news-00065:1</td>\n",
       "      <td>Journalistic Investigations</td>\n",
       "      <td>&lt;ul&gt;\\n&lt;li&gt;&lt;b&gt;Respondent&lt;/b&gt;: It's very importa...</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: So it's mainly the restrictio...</td>\n",
       "      <td>prompted</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: Do you have any data on how m...</td>\n",
       "      <td>sft</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: So, the European Union is tal...</td>\n",
       "      <td>orl</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: What do you expect from Polan...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wikinews-00002:120</td>\n",
       "      <td>Journalistic Investigations</td>\n",
       "      <td>&lt;ul&gt;\\n&lt;li&gt;&lt;b&gt;Respondent&lt;/b&gt;: Maybe. I have a l...</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: Yeah, yeah. The Southern Bapt...</td>\n",
       "      <td>real</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: Yeah. I don't know, but I thi...</td>\n",
       "      <td>orl</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: I did. I grew up in the Midwe...</td>\n",
       "      <td>sft</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: I was raised Catholic, but I ...</td>\n",
       "      <td>prompted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wikinews-00002:200</td>\n",
       "      <td>Journalistic Investigations</td>\n",
       "      <td>&lt;ul&gt;\\n&lt;li&gt;&lt;b&gt;Respondent&lt;/b&gt;: I'm not sure. The...</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: Yes, he did. He said, 'I thin...</td>\n",
       "      <td>orl</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: He's a very dynamic person to...</td>\n",
       "      <td>real</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: I must have made a mistake.  ...</td>\n",
       "      <td>prompted</td>\n",
       "      <td>&lt;b&gt;Elicitor&lt;/b&gt;: Yeah, and he said that he was...</td>\n",
       "      <td>sft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             block_id                       domain  \\\n",
       "0   wikinews-00000:38  Journalistic Investigations   \n",
       "1   wikinews-00000:84  Journalistic Investigations   \n",
       "2    voa-news-00065:1  Journalistic Investigations   \n",
       "3  wikinews-00002:120  Journalistic Investigations   \n",
       "4  wikinews-00002:200  Journalistic Investigations   \n",
       "\n",
       "                                       context_turns  \\\n",
       "0  <ul>\\n<li><b>Respondent</b>: I have very littl...   \n",
       "1  <ul>\\n<li><b>Respondent</b>: Yes there is. Sug...   \n",
       "2  <ul>\\n<li><b>Respondent</b>: It's very importa...   \n",
       "3  <ul>\\n<li><b>Respondent</b>: Maybe. I have a l...   \n",
       "4  <ul>\\n<li><b>Respondent</b>: I'm not sure. The...   \n",
       "\n",
       "                                          response_1 response_1_label  \\\n",
       "0  <b>Elicitor</b>: It looks very painful, your l...             real   \n",
       "1  <b>Elicitor</b>: What about MySpace and YouTub...              orl   \n",
       "2  <b>Elicitor</b>: So it's mainly the restrictio...         prompted   \n",
       "3  <b>Elicitor</b>: Yeah, yeah. The Southern Bapt...             real   \n",
       "4  <b>Elicitor</b>: Yes, he did. He said, 'I thin...              orl   \n",
       "\n",
       "                                          response_2 response_2_label  \\\n",
       "0  <b>Elicitor</b>: It sounds like you've had a l...         prompted   \n",
       "1  <b>Elicitor</b>: So it sounds like you're real...         prompted   \n",
       "2  <b>Elicitor</b>: Do you have any data on how m...              sft   \n",
       "3  <b>Elicitor</b>: Yeah. I don't know, but I thi...              orl   \n",
       "4  <b>Elicitor</b>: He's a very dynamic person to...             real   \n",
       "\n",
       "                                          response_3 response_3_label  \\\n",
       "0              <b>Elicitor</b>: Can you walk at all?              sft   \n",
       "1  <b>Elicitor</b>: Is your goal to raise money o...              sft   \n",
       "2  <b>Elicitor</b>: So, the European Union is tal...              orl   \n",
       "3  <b>Elicitor</b>: I did. I grew up in the Midwe...              sft   \n",
       "4  <b>Elicitor</b>: I must have made a mistake.  ...         prompted   \n",
       "\n",
       "                                          response_4 response_4_label  \n",
       "0  <b>Elicitor</b>: You mentioned your vision. Do...              orl  \n",
       "1  <b>Elicitor</b>: Why do you think there are so...             real  \n",
       "2  <b>Elicitor</b>: What do you expect from Polan...             real  \n",
       "3  <b>Elicitor</b>: I was raised Catholic, but I ...         prompted  \n",
       "4  <b>Elicitor</b>: Yeah, and he said that he was...              sft  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "domain\n",
       "Journalistic Investigations    0.25\n",
       "Judicial Proceedings           0.25\n",
       "Academic Interviews            0.25\n",
       "Oral History                   0.25\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(100, 11)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Diagnostics and save\n",
    "\n",
    "display(df_sampled.head())\n",
    "display(df_sampled[\"domain\"].value_counts(normalize=True))\n",
    "display(df_sampled.shape)\n",
    "\n",
    "df_sampled.to_csv(output_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b7afaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sequential-ieas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
