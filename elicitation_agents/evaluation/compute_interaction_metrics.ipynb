{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd8e9e33",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dfcabe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Imports ----------------\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "from elicitation.metrics.progression import progression\n",
    "from elicitation.metrics.turn_length_ratio import turn_length_ratio\n",
    "from elicitation.metrics.utils import load_dialogues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c011f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Args ----------------\n",
    "# Paths\n",
    "embedding_model_choice_name = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "#cross_encoder_model_choice_name = \"cross-encoder/stsb-roberta-large\"\n",
    "tokenizer_model_choice_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "dataset_choice_name = \"evaluation/generated-utterances-dialogue/20251227T2034-20251227t0851-deepseek-r1-distill-llama-8b-seq-std-m3trained/generated\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Constants\n",
    "PROGRESSION_K = 5\n",
    "PROGRESSION_GAMMA = 0.5\n",
    "#CONVERSATIONAL_CONTROL_K = 2 \n",
    "#CONVERSATIONAL_CONTROL_GAMMA = 0.9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1691dd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Config ----------------\n",
    "timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "with open(\"../../config/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "proj_store = config[\"paths\"][\"proj_store\"]\n",
    "\n",
    "data_path = os.path.join(config[\"paths\"][\"proj_store\"], \"data\")\n",
    "\n",
    "dataset_path = os.path.join(proj_store, dataset_choice_name)\n",
    "\n",
    "models_folderpath = config[\"paths\"][\"models\"]\n",
    "\n",
    "embedding_model_choice = os.path.join(models_folderpath, embedding_model_choice_name)\n",
    "#cross_encoder_model_choice = os.path.join(models_folderpath, cross_encoder_model_choice_name)\n",
    "tokenizer_model_choice = os.path.join(models_folderpath, tokenizer_model_choice_name)\n",
    "\n",
    "\n",
    "save_folder_path = os.path.join(proj_store, \"evaluation\", \"interaction-metrics\", f\"{dataset_choice_name}\")\n",
    "os.makedirs(save_folder_path, exist_ok=True)\n",
    "\n",
    "\n",
    "# Load llama tokenizer\n",
    "tokenizer_model = AutoTokenizer.from_pretrained(tokenizer_model_choice, trust_remote_code=True)\n",
    "\n",
    "# Load sentence embedding model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "embedding_model = SentenceTransformer(embedding_model_choice, device=device)\n",
    "#cross_encoder = CrossEncoder(cross_encoder_model_choice, device=device)\n",
    "\n",
    "\n",
    "\n",
    "#    # Use the chat template to generate properly formatted model input\n",
    "#    context = tokenizer.apply_chat_template(\n",
    "#        messages,\n",
    "#        tokenize=False,\n",
    "#        add_generation_prompt=True  # adds the final assistant stub\n",
    "#    )\n",
    "#    return context\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8b754a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10285 dialogues\n"
     ]
    }
   ],
   "source": [
    "all_dialogues = list(load_dialogues(dataset_path))\n",
    "\n",
    "print(\"Loaded\", len(all_dialogues), \"dialogues\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e940a",
   "metadata": {},
   "source": [
    "## Progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd5e6e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#progression_df = progression(\n",
    "#    dialogues=all_dialogues, \n",
    "#    cross_encoder=cross_encoder, \n",
    "#    k=PROGRESSION_K, \n",
    "#    gamma=PROGRESSION_GAMMA, \n",
    "#    group_by=\"domain\", \n",
    "#    sort_by=\"domain\"\n",
    "#)\n",
    "#\n",
    "#display(progression_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f2629cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progression: 100%|██████████| 10285/10285 [01:37<00:00, 105.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>dialogues</th>\n",
       "      <th>progression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_interviews</td>\n",
       "      <td>1125</td>\n",
       "      <td>0.697155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>journalistic_investigations</td>\n",
       "      <td>183</td>\n",
       "      <td>0.742762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>judicial_proceedings</td>\n",
       "      <td>4949</td>\n",
       "      <td>0.752136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oral_history</td>\n",
       "      <td>4028</td>\n",
       "      <td>0.732349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        domain  dialogues  progression\n",
       "0          academic_interviews       1125     0.697155\n",
       "1  journalistic_investigations        183     0.742762\n",
       "2         judicial_proceedings       4949     0.752136\n",
       "3                 oral_history       4028     0.732349"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progression_df = progression(\n",
    "    dialogues=all_dialogues, \n",
    "    embedding_model=embedding_model, \n",
    "    device=device, \n",
    "    k=PROGRESSION_K, \n",
    "    gamma=PROGRESSION_GAMMA, \n",
    "    group_by=\"domain\", \n",
    "    sort_by=\"domain\"\n",
    ")\n",
    "\n",
    "display(progression_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "170aaa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "progression_df.to_csv(os.path.join(save_folder_path, f\"progression.csv\"), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b19b79c",
   "metadata": {},
   "source": [
    "## Conversational Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee0087f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#control_df = conversational_control(\n",
    "#    dialogues=all_dialogues, \n",
    "#    embedding_model=embedding_model, \n",
    "#    device=device, \n",
    "#    k=CONVERSATIONAL_CONTROL_K, \n",
    "#    gamma=CONVERSATIONAL_CONTROL_GAMMA, \n",
    "#    group_by=\"domain\", \n",
    "#    sort_by=\"domain\"\n",
    "#)\n",
    "#\n",
    "#display(control_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13c363a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "#control_df.to_csv(os.path.join(save_folder_path, f\"conversational_control.csv\"), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c8eda9",
   "metadata": {},
   "source": [
    "## Turn-Length Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05b77641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Turn Length: 100%|██████████| 10285/10285 [00:03<00:00, 2972.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>elicitor_avg_tokens</th>\n",
       "      <th>respondent_avg_tokens</th>\n",
       "      <th>turn_length_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic_interviews</td>\n",
       "      <td>15.26</td>\n",
       "      <td>28.64</td>\n",
       "      <td>1.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>journalistic_investigations</td>\n",
       "      <td>18.27</td>\n",
       "      <td>62.50</td>\n",
       "      <td>3.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>judicial_proceedings</td>\n",
       "      <td>30.59</td>\n",
       "      <td>45.14</td>\n",
       "      <td>1.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oral_history</td>\n",
       "      <td>16.16</td>\n",
       "      <td>58.70</td>\n",
       "      <td>3.632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        domain  elicitor_avg_tokens  respondent_avg_tokens  \\\n",
       "0          academic_interviews                15.26                  28.64   \n",
       "1  journalistic_investigations                18.27                  62.50   \n",
       "2         judicial_proceedings                30.59                  45.14   \n",
       "3                 oral_history                16.16                  58.70   \n",
       "\n",
       "   turn_length_ratio  \n",
       "0              1.877  \n",
       "1              3.421  \n",
       "2              1.476  \n",
       "3              3.632  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "turn_length_df = turn_length_ratio(\n",
    "    dialogues=all_dialogues, \n",
    "    tokenizer_model=tokenizer_model, \n",
    "    group_by=\"domain\", \n",
    "    sort_by=\"domain\"\n",
    ")\n",
    "\n",
    "display(turn_length_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab8604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02a299cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "turn_length_df.to_csv(os.path.join(save_folder_path, f\"turn_length_ratio.csv\"), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00da4108",
   "metadata": {},
   "source": [
    "## Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1d2759b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra columns\n",
    "#progression = progression_df.drop(columns=[\"dialogues\"])\n",
    "#conversational_control = control_df.drop(columns=[\"prompt_response_pairs\"])\n",
    "#turn_length_ratio = turn_length_df.drop(columns=[\"elicitor_avg_tokens\", \"respondent_avg_tokens\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "30d613e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all on 'Domain'\n",
    "#combined_df = progression.merge(conversational_control, on=\"domain\").merge(turn_length_ratio, on=\"domain\")\n",
    "#combined_df = progression.merge(turn_length_ratio, on=\"domain\")\n",
    "\n",
    "\n",
    "#display(combined_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "aeccb88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_df.to_csv(os.path.join(save_folder_path, f\"combined_metrics.csv\"), index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sequential-ieas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
