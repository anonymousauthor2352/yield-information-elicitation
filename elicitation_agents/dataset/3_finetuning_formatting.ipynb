{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acdf5041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Imports ----------------\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "import yaml\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "558dcf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Args ----------------\n",
    "dataset = \"yield-v1-small10pct-factualnovelty-with-rtg\"\n",
    "tokenizer_model = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "TOKEN_LIMIT = 512  # max tokens allowed per dialogue\n",
    "WINDOW_SIZE = 6 # Sliding window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc8f94c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Config ----------------\n",
    "with open(\"../../config/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "proj_store = config[\"paths\"][\"proj_store\"]\n",
    "data_path = os.path.join(proj_store, \"data\")\n",
    "models_folderpath = config[\"paths\"][\"models\"]\n",
    "\n",
    "base_folder = os.path.join(data_path, dataset)\n",
    "output_folder = f\"{base_folder.replace('-with-rtg', '')}-rl\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Initialize tokenizer globally\n",
    "MODEL_NAME = os.path.join(models_folderpath, tokenizer_model) \n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, local_files_only=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f53ff24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dialogue(dialogue, file_path):\n",
    "    turns = dialogue.get(\"turns\", [])\n",
    "    if not turns:\n",
    "        raise ValueError(f\"Dialogue {dialogue.get('dialogue_id')} in {file_path} has no turns.\")\n",
    "\n",
    "    try:\n",
    "        domain = dialogue[\"domain\"]\n",
    "    except KeyError:\n",
    "        raise ValueError(f\"Missing required field 'domain' in dialogue {dialogue.get('dialogue_id')} in {file_path}\")\n",
    "\n",
    "    system_prompt = f\"Act as an information elicitation agent for {domain.replace('_', ' ')}.\"\n",
    "\n",
    "    # skip leading elicitor-only turns\n",
    "    index = 0\n",
    "    while index < len(turns) and turns[index][\"role\"] == \"elicitor\":\n",
    "        index += 1\n",
    "\n",
    "    if index >= len(turns):\n",
    "        raise ValueError(f\"Dialogue {dialogue.get('dialogue_id')} in {file_path} has no respondent turn to start with.\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Build merged blocks + track which turn indices they came from\n",
    "    merged_blocks = []\n",
    "    #block_turn_indices = []\n",
    "    block_start_indices = []   \n",
    "    block_end_indices = []\n",
    "    current_role = None\n",
    "    utterances = []\n",
    "\n",
    "    for i in range(index, len(turns)):\n",
    "        turn = turns[i]\n",
    "        role = turn[\"role\"]\n",
    "        utterance = turn[\"utterance\"].strip()\n",
    "\n",
    "        if current_role is None:\n",
    "            current_role = role\n",
    "            utterances = [utterance]\n",
    "            start_index = i\n",
    "        elif role == current_role:\n",
    "            utterances.append(utterance)\n",
    "        else:\n",
    "            merged_content = \"\\n\\n\".join(utterances)\n",
    "            merged_blocks.append((current_role, merged_content))\n",
    "            block_start_indices.append(start_index)\n",
    "            block_end_indices.append(i - 1)\n",
    "\n",
    "            current_role = role\n",
    "            utterances = [utterance]\n",
    "            start_index = i\n",
    "\n",
    "    if utterances:\n",
    "        merged_content = \"\\n\\n\".join(utterances)\n",
    "        merged_blocks.append((current_role, merged_content))\n",
    "        block_start_indices.append(start_index)\n",
    "        block_end_indices.append(len(turns) - 1)\n",
    "\n",
    "    # SLIDING WINDOW \n",
    "    \n",
    "    for window_start in range(len(merged_blocks) - WINDOW_SIZE + 1):\n",
    "        window = merged_blocks[window_start : window_start + WINDOW_SIZE]\n",
    "\n",
    "        if window[-1][0] == \"elicitor\":\n",
    "            ensuing_index_in_blocks = window_start + WINDOW_SIZE\n",
    "            ensuing_score = None\n",
    "            ensuing_return = None\n",
    "\n",
    "            if ensuing_index_in_blocks < len(merged_blocks):\n",
    "                ensuing_block_role = merged_blocks[ensuing_index_in_blocks][0]\n",
    "                ensuing_block_last_turn = block_end_indices[ensuing_index_in_blocks]\n",
    "                if ensuing_block_role == \"respondent\":\n",
    "                    ensuing_turn = turns[ensuing_block_last_turn]\n",
    "                    ensuing_score = ensuing_turn.get(\"factual_novelty_score\")\n",
    "                    ensuing_return = ensuing_turn.get(\"return_to_go\")\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # Build message history\n",
    "            messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "            for role, content in window:\n",
    "                if role == \"elicitor\":\n",
    "                    messages.append({\"role\": \"assistant\", \"content\": content})\n",
    "                elif role == \"respondent\":\n",
    "                    messages.append({\"role\": \"user\", \"content\": content})\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected role: {role}\")\n",
    "\n",
    "            # Format conversation and count tokens\n",
    "            chat_text = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=False\n",
    "            )\n",
    "            tokens = tokenizer(chat_text, return_tensors=None, add_special_tokens=False)[\"input_ids\"]\n",
    "            token_count = len(tokens)\n",
    "\n",
    "            if token_count <= TOKEN_LIMIT:\n",
    "                first_block_turn_index = block_start_indices[window_start]\n",
    "                \n",
    "                results.append({\n",
    "                    \"block_id\": f\"{dialogue.get('dialogue_id')}:{first_block_turn_index}\",\n",
    "                    \"domain\": domain,\n",
    "                    \"factual_novelty_score\": ensuing_score,\n",
    "                    \"return_to_go\": ensuing_return,\n",
    "                    \"messages\": messages,\n",
    "                })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_file(input_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        dialogues = json.load(f)\n",
    "\n",
    "    if not isinstance(dialogues, list):\n",
    "        raise ValueError(f\"Expected list of dialogues in file {input_file}, found {type(dialogues)}\")\n",
    "\n",
    "    processed_dialogues = []\n",
    "\n",
    "    for _, dialogue in enumerate(dialogues):\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            processed_windows = process_dialogue(dialogue, input_file)\n",
    "            for window in processed_windows:\n",
    "                processed_dialogues.append(json.dumps(window, ensure_ascii=False))\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error in {input_file}: {e}\")\n",
    "\n",
    "    return processed_dialogues\n",
    "\n",
    "\n",
    "\n",
    "def process_split(input_folder, output_folder):\n",
    "    json_files = [f for f in os.listdir(input_folder) if f.endswith('.json')]\n",
    "\n",
    "    for json_file in json_files:\n",
    "        file_path = os.path.join(input_folder, json_file)\n",
    "        processed = process_file(file_path)\n",
    "\n",
    "        output_file_path = os.path.join(output_folder, json_file.replace('.json', '.jsonl'))\n",
    "\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as f_out:\n",
    "            for line in processed:\n",
    "                f_out.write(line + '\\n')\n",
    "\n",
    "        print(f\"Processed {len(processed)} dialogues from {json_file} into {output_file_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca708389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2528 dialogues from train-001.json into /data/sequential-ieas/data/yield-v1-small10pct-factualnovelty-rl/train/train-001.jsonl\n",
      "Processed 8702 dialogues from train-000.json into /data/sequential-ieas/data/yield-v1-small10pct-factualnovelty-rl/train/train-000.jsonl\n",
      "Processed 2040 dialogues from dev-000.json into /data/sequential-ieas/data/yield-v1-small10pct-factualnovelty-rl/dev/dev-000.jsonl\n",
      "Processed 1044 dialogues from test-000.json into /data/sequential-ieas/data/yield-v1-small10pct-factualnovelty-rl/test/test-000.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Procedure\n",
    "splits = [\"train\", \"dev\", \"test\"]\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for split in splits:\n",
    "    input_split_folder = os.path.join(base_folder, split)\n",
    "    output_split_folder = os.path.join(output_folder, split)\n",
    "    os.makedirs(output_split_folder, exist_ok=True)\n",
    "\n",
    "    process_split(input_split_folder, output_split_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sequential-ieas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
