{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Imports ----------------\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import yaml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Config ----------------\n",
    "with open(\"../../../config/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "data_folder = os.path.join(config[\"paths\"][\"proj_store\"], \"data\")\n",
    "\n",
    "# Input and output folder paths\n",
    "input_folder = f\"{data_folder}/intermediate_data/02_manual_tagging\"  \n",
    "output_folder = f\"{data_folder}/intermediate_data/03_json_conversion\"  \n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_txt_to_json(input_folder, output_folder):\n",
    "\n",
    "    all_errors = []  # List to collect all validation errors\n",
    "\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                input_file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Read and parse the .txt file\n",
    "                with open(input_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    content = f.read()\n",
    "                \n",
    "                metadata, dialogue = parse_content(content)\n",
    "\n",
    "                # Validate speaker consistency but do NOT raise an error immediately\n",
    "                validate_speakers(metadata, dialogue, file, all_errors)\n",
    "\n",
    "                # Prepare the JSON data\n",
    "                json_data = {\n",
    "                    \"metadata\": metadata,\n",
    "                    \"turns\": dialogue\n",
    "                }\n",
    "                \n",
    "                # Determine output file path\n",
    "                relative_path = os.path.relpath(root, input_folder)\n",
    "                output_dir = os.path.join(output_folder, relative_path)\n",
    "                os.makedirs(output_dir, exist_ok=True)\n",
    "                output_file_path = os.path.join(output_dir, f\"{os.path.splitext(file)[0]}.json\")\n",
    "                \n",
    "                # Write the JSON file\n",
    "                with open(output_file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "                    json.dump(json_data, json_file, indent=4)\n",
    "\n",
    "    # After all files are processed, raise all errors at once\n",
    "    if all_errors:\n",
    "        raise ValueError(\"Speaker mismatches found:\\n\" + \"\\n\".join(all_errors))\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    \n",
    "    text = text.replace(\"\\n\", \" \")  \n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)  \n",
    "    return text.strip()\n",
    "\n",
    "def parse_content(content):\n",
    "\n",
    "    \n",
    "    # Split the file into metadata and dialogue parts\n",
    "    sections = content.split(\"--- dialogue ---\")\n",
    "    metadata_section = sections[0].replace(\"--- metadata ---\", \"\").strip()\n",
    "    dialogue_section = sections[1].strip() if len(sections) > 1 else \"\"\n",
    "    \n",
    "    # Parse metadata into a dictionary\n",
    "    metadata = {}\n",
    "    for line in metadata_section.split(\"\\n\"):\n",
    "        if \": \" in line:\n",
    "            key, value = line.split(\": \", 1)\n",
    "            if key.strip().lower() in [\"elicitors\", \"respondents\"]:  # Convert these fields to a list\n",
    "                metadata[key.strip().lower()] = [item.strip() for item in value.split(\",\")]\n",
    "            else:\n",
    "                metadata[key.strip().lower()] = value.strip()\n",
    "    \n",
    "    # Extract elicitors and respondents for speaker identification\n",
    "    elicitors = metadata.get(\"elicitors\", [])  # Lowercased keys for consistency\n",
    "    respondents = metadata.get(\"respondents\", [])\n",
    "    \n",
    "    # Parse dialogue into a list of turns\n",
    "    dialogue = []\n",
    "    speaker_pattern = r\"<SPEAKER>(.*?)</SPEAKER>\"\n",
    "    timestamp_pattern = r\"<TIMESTAMP>(.*?)</TIMESTAMP>\"\n",
    "    segments = re.split(speaker_pattern, dialogue_section)\n",
    "    \n",
    "    current_speaker = None\n",
    "    for i, segment in enumerate(segments):\n",
    "        if i % 2 == 1:  # Odd indices are speaker tags\n",
    "            current_speaker = segment.strip()\n",
    "        elif current_speaker:  # Even indices are dialogue associated with the last speaker\n",
    "            role = \"elicitor\" if current_speaker in elicitors else \"respondent\"\n",
    "            \n",
    "            # Extract timestamp if present\n",
    "            timestamp_match = re.search(timestamp_pattern, segment)\n",
    "            timestamp = timestamp_match.group(1).strip() if timestamp_match else \"\"\n",
    "            cleaned_text = clean_text(re.sub(timestamp_pattern, \"\", segment))  # Remove timestamp from text\n",
    "            \n",
    "            dialogue.append({\n",
    "                \"speaker\": current_speaker,\n",
    "                \"role\": role,\n",
    "                \"timestamp\": timestamp,\n",
    "                \"utterance\": cleaned_text\n",
    "            })\n",
    "    \n",
    "    return metadata, dialogue\n",
    "\n",
    "def validate_speakers(metadata, dialogue, filename, errors_list):\n",
    "\n",
    "    metadata_elicitors = set(metadata.get(\"elicitors\", []))\n",
    "    metadata_respondents = set(metadata.get(\"respondents\", []))\n",
    "\n",
    "    dialogue_speakers = {turn[\"speaker\"] for turn in dialogue}\n",
    "\n",
    "    # Collect inconsistencies\n",
    "    missing_from_dialogue = (metadata_elicitors | metadata_respondents) - dialogue_speakers\n",
    "    extra_in_dialogue = dialogue_speakers - (metadata_elicitors | metadata_respondents)\n",
    "\n",
    "    if missing_from_dialogue or extra_in_dialogue:\n",
    "        error_message = f\"\\nError in file '{filename}':\\n\" \\\n",
    "                        f\"- Speakers in metadata but missing from dialogue: {list(missing_from_dialogue)}\\n\" \\\n",
    "                        f\"- Speakers in dialogue but not in metadata: {list(extra_in_dialogue)}\"\n",
    "        errors_list.append(error_message)  # Collect errors instead of stopping execution\n",
    "\n",
    "\n",
    "\n",
    "# Run the parsing function\n",
    "parse_txt_to_json(input_folder, output_folder)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yield_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
