{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Imports ----------------\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Config ----------------\n",
    "with open(\"../../../config/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "data_folder = os.path.join(config[\"paths\"][\"proj_store\"], \"data\")\n",
    "\n",
    "\n",
    "input_directory = f\"{data_folder}/raw_data/machine_collected/jsc_oral_history\"\n",
    "updated_df = pd.read_csv(f\"{input_directory}/metadata.csv\")\n",
    "\n",
    "output_directory = f\"{data_folder}/intermediate_data/01_txt_files/jsc_oral_history\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Setup ----------------\n",
    "# Initialize a counter\n",
    "counter = 0\n",
    "folder_name = os.path.basename(output_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each URL and extract text\n",
    "for index, row in updated_df.iterrows():\n",
    "    \n",
    "    original_filename = row['original_file_name']\n",
    "\n",
    "    # Convert .htm to .html to match the stored files\n",
    "    base_filename = os.path.splitext(original_filename)[0]  # Removes .htm\n",
    "    stored_filename = f\"{base_filename}.html\"  # Ensures we look for .html files\n",
    "\n",
    "    html_file_path = os.path.join(input_directory, stored_filename)\n",
    "\n",
    "    try:\n",
    "        # Read the local HTML file\n",
    "        with open(html_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            soup = BeautifulSoup(file, \"html.parser\")\n",
    "\n",
    "\n",
    "        \n",
    "        # Prepare metadata section\n",
    "        metadata_lines = [\"--- metadata ---\"]\n",
    "        for column in updated_df.columns:\n",
    "            metadata_lines.append(f\"{column}: {row[column]}\")\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # Loop through all <tbody> elements until we find one containing <h4> or <h5>\n",
    "        for tbody in soup.find_all(\"tbody\"):\n",
    "            h4_h5_texts = []\n",
    "            \n",
    "            for tag in tbody.find_all([\"h4\", \"h5\"]):\n",
    "                # Convert <br> to a temporary placeholder before extracting text\n",
    "                for br in tag.find_all(\"br\"):\n",
    "                    br.replace_with(\" ||| \")  # Using '|||' as a temporary separator\n",
    "\n",
    "                # Extract text with placeholders for proper splitting\n",
    "                text = tag.get_text(\" \", strip=True).strip(\" |||\")  # Ensure words remain together\n",
    "                text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove excessive spaces\n",
    "\n",
    "                # Process the text and split where needed\n",
    "                parts = text.split(\" ||| \")\n",
    "                cleaned_text = []\n",
    "                for part in parts:\n",
    "                    part = part.strip()\n",
    "                    if cleaned_text and re.match(r\"^[A-Z][a-z]+\\s[A-Z]\\.\", part):  \n",
    "                        \n",
    "                        cleaned_text[-1] += \" \" + part \n",
    "                    else:\n",
    "                        cleaned_text.append(part) \n",
    "\n",
    "                if cleaned_text:  \n",
    "                    h4_h5_texts.append(\"\\n\".join(cleaned_text))\n",
    "\n",
    "            if h4_h5_texts:  \n",
    "                h4_h5_texts = [line for line in h4_h5_texts if line.strip()] \n",
    "                metadata_lines.extend(h4_h5_texts) \n",
    "                break \n",
    "\n",
    "        \n",
    "\n",
    "        # Replace <strong>Speaker:</strong> with <SPEAKER>Speaker:</SPEAKER>\n",
    "        for strong_tag in soup.find_all(\"strong\"):\n",
    "            if strong_tag.text.strip().endswith(\":\"):\n",
    "                speaker_name = strong_tag.text.strip().rstrip(\":\")  \n",
    "                strong_tag.string = f\"<SPEAKER>{speaker_name}</SPEAKER>\"\n",
    "\n",
    "        # Remove all <a> tags but keep their content\n",
    "        for a_tag in soup.find_all(\"a\"):\n",
    "            a_tag.unwrap()\n",
    "\n",
    "        # Extract text from the modified HTML\n",
    "        text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "        # Remove everything after \"[End of interview]\" with flexible matching\n",
    "        end_pattern = re.compile(r\"\\[\\s*End\\s+of\\s+interview\\s*\\]\", re.IGNORECASE)\n",
    "        match = end_pattern.search(text)\n",
    "        if match:\n",
    "            text = text[: match.start()]  # Cut off everything from [End of interview] onward\n",
    "\n",
    "\n",
    "\n",
    "        # Convert text into a list of lines\n",
    "        text_lines = text.split(\"\\n\")\n",
    "\n",
    "        # Find the first <SPEAKER> tag and determine where to insert \"--- dialogue ---\"\n",
    "        for i, line in enumerate(text_lines):\n",
    "            if line.startswith(\"<SPEAKER>\"):\n",
    "                dialogue_insert_index = i  # Position where \"--- dialogue ---\" will be inserted\n",
    "\n",
    "                # Extract the lines before the first <SPEAKER>\n",
    "                pre_speaker_lines = text_lines[:i]\n",
    "\n",
    "                ## Process the pre-SPEAKER lines\n",
    "                new_pre_speaker_lines = []\n",
    "                for pre_line in pre_speaker_lines:\n",
    "                    stripped_line = pre_line.strip()\n",
    "\n",
    "\n",
    "                ## Replace text_lines before <SPEAKER> with only the cleaned-up version\n",
    "                text_lines = new_pre_speaker_lines + text_lines[i:]\n",
    "\n",
    "                # Insert \"--- dialogue ---\" before the first <SPEAKER>\"\n",
    "                text_lines.insert(len(new_pre_speaker_lines), \"\\n\\n--- dialogue ---\")\n",
    "\n",
    "                break \n",
    "\n",
    "                \n",
    "                \n",
    "        # Consolidate metadata and text before processing further\n",
    "        formatted_metadata = \"\\n\".join(metadata_lines)  # Convert metadata list to a string\n",
    "        \n",
    "        formatted_metadata = re.sub(r\"(?i)Interviewed by \", \"\", formatted_metadata)  # Case-insensitive replace\n",
    "        #print(metadata_lines)\n",
    "        \n",
    "        \n",
    "        formatted_text = \"\\n\".join(text_lines)  # Convert cleaned text to a string\n",
    "        \n",
    "        \n",
    "        # Remove lines that start with \": \" (preserving other content)\n",
    "        formatted_text = re.sub(r\"^:\\s+\", \"\", formatted_text, flags=re.MULTILINE)\n",
    "\n",
    "        # Combine metadata and main text before modifying the metadata section\n",
    "        text = f\"{formatted_metadata}\\n\\n{formatted_text}\"\n",
    "                \n",
    "\n",
    "\n",
    "        # Titles to prepend\n",
    "        titles = [\n",
    "            \"subcollection: \",\n",
    "            \"subtitle: \",\n",
    "            \"subtitle_interviewee: \",\n",
    "            \"interviewers: \",\n",
    "            \"location_date: \"\n",
    "        ]\n",
    "\n",
    "        # Split text into sections\n",
    "        sections = text.split(\"--- dialogue ---\")\n",
    "        metadata_section = sections[0].strip()  # Ensure no leading/trailing spaces\n",
    "        dialogue_section = \"--- dialogue ---\" + sections[1] if len(sections) > 1 else \"\"\n",
    "\n",
    "        # Extract metadata lines\n",
    "        metadata_lines = metadata_section.splitlines()\n",
    "        metadata_header = metadata_lines[0]  # Preserve the \"--- metadata ---\" header\n",
    "        metadata_content = metadata_lines[1:]  # Actual metadata lines\n",
    "\n",
    "        # Ensure at least 5 lines exist\n",
    "        if len(metadata_content) >= 5:\n",
    "            # Modify the last 5 lines by prepending the corresponding variable titles\n",
    "            for i in range(5):\n",
    "                metadata_content[-5 + i] = titles[i] + metadata_content[-5 + i]\n",
    "\n",
    "        \n",
    "        # Replace \" and \" with \", \" only in the interviewers line\n",
    "        for i, line in enumerate(metadata_content):\n",
    "            if line.startswith(\"interviewers: \"):\n",
    "                metadata_content[i] = line.replace(\" and \", \", \")\n",
    "                \n",
    "        # Reconstruct the metadata section\n",
    "        new_metadata_section = \"\\n\".join([metadata_header] + metadata_content)\n",
    "        \n",
    "        \n",
    "\n",
    "        # Reconstruct the final text\n",
    "        text = f\"{new_metadata_section}\\n\\n{dialogue_section}\"\n",
    "        \n",
    "\n",
    "        # Ensure text_lines is extracted properly from text\n",
    "        text_lines = text.splitlines()  # Splitting text into a list of lines\n",
    "                \n",
    "    \n",
    "        \n",
    "    \n",
    "        # Post-process text_lines to format dialogue properly\n",
    "        processed_lines = []\n",
    "        inside_dialogue = False  # Flag to track when we are inside the dialogue section\n",
    "\n",
    "        for line in text_lines:\n",
    "            stripped_line = line.strip()\n",
    "\n",
    "            # Detect when dialogue starts\n",
    "            if stripped_line == \"--- dialogue ---\":\n",
    "                inside_dialogue = True\n",
    "                processed_lines.append(line)  # Keep the \"--- dialogue ---\" line as is\n",
    "                continue\n",
    "\n",
    "            # If inside the dialogue, format correctly\n",
    "            if inside_dialogue:\n",
    "                if stripped_line.startswith(\"<SPEAKER>\"):  \n",
    "                    # Ensure a blank line before each speaker tag\n",
    "                    processed_lines.append(\"\\n\" + stripped_line)\n",
    "                elif stripped_line:  \n",
    "                    # If the line does NOT start at the beginning, remove leading spaces and merge\n",
    "                    if line.startswith(\" \"):  \n",
    "                        processed_lines[-1] += \" \" + stripped_line  # Merge into previous line\n",
    "                    else:\n",
    "                        processed_lines.append(stripped_line)  # Start a new line normally\n",
    "            else:\n",
    "                processed_lines.append(line)  # Preserve metadata as is\n",
    "\n",
    "        # Convert the cleaned-up lines back into a full formatted text\n",
    "        formatted_text = \"\\n\".join(processed_lines)\n",
    "        \n",
    "        # Combine everything into a structured format\n",
    "        #formatted_text = \"\\n\".join(metadata_lines) + \"\\n\" + \"\\n\".join(processed_lines)\n",
    "        \n",
    "        \n",
    "        # Add literal \\n\\n after each utterance line (non-empty, non-speaker) inside the dialogue section\n",
    "        lines = formatted_text.splitlines()\n",
    "        new_lines = []\n",
    "        inside_dialogue = False\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            stripped = line.strip()\n",
    "            if stripped == \"--- dialogue ---\":\n",
    "                inside_dialogue = True\n",
    "                new_lines.append(line)\n",
    "                continue\n",
    "\n",
    "            if inside_dialogue:\n",
    "                if stripped.startswith(\"<SPEAKER>\"):\n",
    "                    new_lines.append(line)\n",
    "                elif stripped != \"\":\n",
    "                    # check next non-empty line\n",
    "                    next_nonempty = \"\"\n",
    "                    for j in range(i + 1, len(lines)):\n",
    "                        next_line = lines[j].strip()\n",
    "                        if next_line != \"\":\n",
    "                            next_nonempty = next_line\n",
    "                            break\n",
    "\n",
    "                    if not next_nonempty.startswith(\"<SPEAKER>\") and next_nonempty != \"\":\n",
    "                        # add \\n\\n only if the next nonempty line is NOT a speaker tag\n",
    "                        new_lines.append(f\"{line}\\\\n\\\\n\")\n",
    "                    else:\n",
    "                        new_lines.append(line)\n",
    "                else:\n",
    "                    new_lines.append(line)  # preserve empty lines\n",
    "            else:\n",
    "                new_lines.append(line)  # preserve metadata\n",
    "\n",
    "        formatted_text = \"\\n\".join(new_lines)\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "        # Generate the new filename with the folder name and a five-digit counter\n",
    "        new_filename = f\"{folder_name}_{counter:05d}.txt\"\n",
    "        counter += 1  # Increment the counter\n",
    "\n",
    "        # Save the extracted text with metadata\n",
    "        filename = os.path.join(output_directory, new_filename)\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(formatted_text)\n",
    "        \n",
    "        print(f\"Saved text from {original_filename} to {filename}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {html_file_path}. Skipping...\")\n",
    "        continue  # Skip to the next file\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error processing {html_file_path}: {e}\")\n",
    "        continue\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yield_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
