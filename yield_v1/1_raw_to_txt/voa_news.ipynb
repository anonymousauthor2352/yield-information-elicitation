{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Imports ----------------\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Config ----------------\n",
    "with open(\"../../../config/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "data_folder = os.path.join(config[\"paths\"][\"proj_store\"], \"data\")\n",
    "\n",
    "input_directory = f\"{data_folder}/raw_data/machine_collected/voa_news\"\n",
    "metadata_df = pd.read_csv(f\"{input_directory}/metadata.csv\")\n",
    "\n",
    "output_directory = f\"{data_folder}/intermediate_data/01_txt_files/voa_news\"\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Setup ----------------\n",
    "# skip\n",
    "titles_to_skip = [\n",
    "\n",
    "    \"112580.html\",\n",
    "    \"114580.html\",\n",
    "    \"268513.html\",\n",
    "    \"2732030.html\",\n",
    "    \"2863112.html\",\n",
    "    \"2871518.html\",\n",
    "    \"2985297.html\",\n",
    "    \"3266622.html\",\n",
    "    \"344951.html\",\n",
    "    \"374633.html\",\n",
    "    \"376070.html\",\n",
    "    \"376245.html\",\n",
    "    \"383312.html\",\n",
    "    \"387525.html\",\n",
    "    \"389494.html\",\n",
    "    \"394878.html\",\n",
    "    \"398149.html\",\n",
    "    \"403086.html\",\n",
    "    \"4194017.html\",\n",
    "    \"4212372.html\",\n",
    "    \"4322596.html\",\n",
    "    \"4408188.html\",\n",
    "    \"4438375.html\",\n",
    "    \"4518257.html\",\n",
    "    \"4525809.html\",\n",
    "    \"542128.html\",\n",
    "    \"550425.html\",\n",
    "    \"552689.html\",\n",
    "    \"6104227.html\",\n",
    "    \"6104382.html\",\n",
    "    \"6104700.html\",\n",
    "    \"6106248.html\",\n",
    "    \"6106249.html\",\n",
    "    \"6110275.html\",\n",
    "    \"6110570.html\",\n",
    "    \"6110571.html\",\n",
    "    \"6110909.html\",\n",
    "    \"6110921.html\",\n",
    "    \"6111199.html\",\n",
    "    \"6112074.html\",\n",
    "    \"6115793.html\",\n",
    "    \"6174254.html\",\n",
    "    \"6191106.html\",\n",
    "    \"6191758.html\",\n",
    "    \"6194626.html\",\n",
    "    \"6402952.html\",\n",
    "    \"7931365.html\",\n",
    "    \"7024481.html\",\n",
    "    \"7018988.html\",\n",
    "    \"7107157.html\",\n",
    "    \"7199021.html\",\n",
    "    \"7288160.html\",\n",
    "    \"7305324.html\",\n",
    "    \"7328757.html\",\n",
    "    \"7849048.html\",\n",
    "    \"7904825.html\",\n",
    "    \"2761200.html\",\n",
    "    \"4795487.html\",\n",
    "    \"6735421.html\",\n",
    "    \"6827986.html\",\n",
    "    \"6867451.html\",\n",
    "    \"6895900.html\",\n",
    "    \"6906731.html\",\n",
    "    \"6913900.html\",\n",
    "    \"6948475.html\",\n",
    "    \"6958471.html\",\n",
    "    \"6997667.html\",\n",
    "    \"7031781.html\",\n",
    "    \"7356091.html\",\n",
    "    \"7532913.html\",\n",
    "    \"151345.html\",\n",
    "    \"388818.html\",\n",
    "    \"4254944.html\",\n",
    "    \"551592.html\",\n",
    "    \"6432001.html\",\n",
    "    \"6658514.html\",\n",
    "    \"6759424.html\",\n",
    "    \"6850939.html\",\n",
    "    \"6906747.html\",\n",
    "    \"6995149.html\",\n",
    "    \"7057905.html\",\n",
    "    \"6546950.html\",\n",
    "    \"6877826.html\",\n",
    "\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract folder name from input path for naming convention\n",
    "folder_name = os.path.basename(input_directory)\n",
    "\n",
    "\n",
    "def extract_voa_article_from_html(file_path, metadata, success_counter):\n",
    "    \"\"\"Extracts and saves VOA News article text from an HTML file with metadata.\"\"\"\n",
    "    try:\n",
    "        # Check if the title exists in metadata\n",
    "        article_title = metadata.get(\"original_file_name\", \"\").strip()\n",
    "\n",
    "        if article_title in titles_to_skip:\n",
    "            print(f\"Skipping '{article_title}' as it is in the skip list.\")\n",
    "            return False  # Skip this file\n",
    "\n",
    "        # Read the HTML content\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            soup = BeautifulSoup(file, \"html.parser\")\n",
    "\n",
    "        # Extract the article content\n",
    "        article_body = soup.find(\"div\", class_=\"wsw\")\n",
    "        if article_body:\n",
    "            paragraphs = [p.get_text(\"\\n\", strip=True) for p in article_body.find_all(\"p\")]\n",
    "            article_text = \"\\n\".join(paragraphs)  # Ensure proper text formatting\n",
    "\n",
    "        if not article_text:\n",
    "            print(f\"Warning: No text found in {file_path}\")\n",
    "            return False  # Process not successful, do not increase counter\n",
    "\n",
    "        # Format metadata\n",
    "        metadata_text = \"--- metadata ---\\n\"\n",
    "        metadata_text += \"\\n\".join(f\"{key}: {value}\" for key, value in metadata.items())\n",
    "\n",
    "        # Add spacing and the `--- dialogue ---` tag\n",
    "        formatted_text = f\"{metadata_text}\\n\\n--- dialogue ---\\n\\n{article_text}\"\n",
    "\n",
    "        # Generate filename with folder name and 5-digit counter\n",
    "        filename = os.path.join(output_directory, f\"{folder_name}_{success_counter:05d}.txt\")\n",
    "\n",
    "        # Save to a .txt file\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(formatted_text)\n",
    "\n",
    "        print(f\"Saved: {filename}\")\n",
    "        return True  # Successful processing\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return False  # Process failed, do not increase counter\n",
    "\n",
    "# Initialize success counter\n",
    "success_counter = 0\n",
    "\n",
    "# Process all HTML files in the input directory\n",
    "for file_name in sorted(os.listdir(input_directory)):\n",
    "    if file_name.endswith(\".html\"):\n",
    "        file_path = os.path.join(input_directory, file_name)\n",
    "\n",
    "        # Find the corresponding metadata entry\n",
    "        matching_row = metadata_df[metadata_df['document_link'].str.contains(file_name, na=False)]\n",
    "        metadata = matching_row.to_dict(orient=\"records\")[0] if not matching_row.empty else {}\n",
    "\n",
    "        # Only increase counter if processing is successful\n",
    "        if extract_voa_article_from_html(file_path, metadata, success_counter):\n",
    "            success_counter += 1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yield_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
