{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Imports ----------------\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Config ----------------\n",
    "with open(\"../../../config/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "data_folder = os.path.join(config[\"paths\"][\"proj_store\"], \"data\")\n",
    "\n",
    "\n",
    "# Input and output directories\n",
    "input_directory = f\"{data_folder}/intermediate_data/03_json_conversion\"\n",
    "output_directory = f\"{data_folder}/yield_v1_base\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Setup ----------------\n",
    "# use:\n",
    "folder_mapping = {\n",
    "    # harvard_dataverse\n",
    "    \"harvard_dataverse/ai_feedback_moving_beyond\": (\"ai_feedback_moving_beyond\", \"academic_interviews\", \"harvard_dataverse\"),\n",
    "    \"harvard_dataverse/biodiversity_offsetting\": (\"biodiversity_offsetting\", \"academic_interviews\", \"harvard_dataverse\"),\n",
    "    \"harvard_dataverse/covid_19_threshold\": (\"covid_19_threshold\", \"academic_interviews\", \"harvard_dataverse\"),\n",
    "    \"harvard_dataverse/drivers_of_food_choice\": (\"drivers_of_food_choice\", \"academic_interviews\", \"harvard_dataverse\"),\n",
    "    \"harvard_dataverse/leaders_leading_organizational_change\": (\"leaders_leading_organizational_change\", \"academic_interviews\", \"harvard_dataverse\"),\n",
    "    \"harvard_dataverse/relationship_building_around_farmers\": (\"relationship_building_around_farmers\", \"academic_interviews\", \"harvard_dataverse\"),\n",
    "    \"harvard_dataverse/healthworker_interviews/lira\": (\"healthworker_interviews\", \"academic_interviews\", \"harvard_dataverse\"),\n",
    "    \"harvard_dataverse/healthworker_interviews/mbarara\": (\"healthworker_interviews\", \"academic_interviews\", \"harvard_dataverse\"),\n",
    "    \"harvard_dataverse/healthworker_interviews/wakiso\": (\"healthworker_interviews\", \"academic_interviews\", \"harvard_dataverse\"),\n",
    "\n",
    "    # jfk_library\n",
    "    \"jfk_library/returned_peace_corps_volunteers\": (\"returned_peace_corps_volunteers\", \"oral_history\", \"jfk_library\"),\n",
    "\n",
    "    # news\n",
    "    \"voa_news\": (\"voa_news\", \"journalistic_investigations\", \"voa_news\"),\n",
    "    \"wikinews\": (\"wikinews\", \"journalistic_investigations\", \"wikinews\"),\n",
    "\n",
    "    # nasa\n",
    "    \"jsc_oral_history\": (\"jsc_oral_history\", \"oral_history\", \"jsc_oral_history\"),\n",
    "\n",
    "    # nara\n",
    "    \"nara/assembly_oral_histories\": (\"assembly_oral_histories\", \"oral_history\", \"nara\"),\n",
    "    \"nara/nprc_oral_histories\": (\"nprc_oral_histories\", \"oral_history\", \"nara\"),\n",
    "    \"nara/oral_history_at_the_national_archives\": (\"oral_history_at_the_national_archives\", \"oral_history\", \"nara\"),\n",
    "    \"nara/veterans_oral_histories\": (\"veterans_oral_histories\", \"oral_history\", \"nara\"),\n",
    "\n",
    "    # other_collections\n",
    "    \"other_collections/flu_vaccination_interviews\": (\"flu_vaccination_interviews\", \"academic_interviews\", \"other_collections\"),\n",
    "\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_files(input_dir, output_dir, folder_mapping):\n",
    "    def process_folder(input_folder, output_folder, counters):\n",
    "        Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Get the collection, domain, and subdomain for this folder\n",
    "        relative_output_folder = os.path.relpath(output_folder, output_dir)\n",
    "        collection, domain, broad_source = folder_mapping.get(relative_output_folder, (\"\", \"\", \"\"))\n",
    "\n",
    "        # Generate the collection name in the desired format\n",
    "        collection_id = collection.replace(\"_\", \"-\").replace(\" \", \"-\")\n",
    "\n",
    "        # Initialize the counter for this collection if not already present\n",
    "        if collection_id not in counters:\n",
    "            counters[collection_id] = 0\n",
    "\n",
    "        # Get a sorted list of files and directories in the folder\n",
    "        items = sorted(os.listdir(input_folder))\n",
    "\n",
    "        for item in items:\n",
    "            item_path = os.path.join(input_folder, item)\n",
    "            output_item_path = os.path.join(output_folder, item)\n",
    "\n",
    "            if os.path.isdir(item_path):\n",
    "                # Recursively process subfolders\n",
    "                process_folder(item_path, output_item_path, counters)\n",
    "            elif item.endswith('.json'):\n",
    "                # Process JSON files\n",
    "                with open(item_path, 'r', encoding='utf-8') as infile:\n",
    "                    data = json.load(infile)\n",
    "\n",
    "                    # Extract and remove elicitors and respondents from metadata\n",
    "                    elicitors = data[\"metadata\"].pop(\"elicitors\", [])\n",
    "                    respondents = data[\"metadata\"].pop(\"respondents\", [])\n",
    "                    title = data[\"metadata\"].pop(\"title\", \"\")\n",
    "\n",
    "                    # Ensure elicitors and respondents are lists\n",
    "                    if isinstance(elicitors, str):\n",
    "                        elicitor_list = [i.strip() for i in elicitors.split(\",\") if i.strip()]\n",
    "                    else:\n",
    "                        elicitor_list = [i.strip() for i in elicitors if isinstance(i, str) and i.strip()]\n",
    "\n",
    "                    if isinstance(respondents, str):\n",
    "                        respondent_list = [t.strip() for t in respondents.split(\",\") if t.strip()]\n",
    "                    else:\n",
    "                        respondent_list = [t.strip() for t in respondents if isinstance(t, str) and t.strip()]\n",
    "\n",
    "                    # Create new top-level keys\n",
    "                    dialogue_id = f\"{collection_id}-{counters[collection_id]:05d}\"\n",
    "                    new_data = {\n",
    "                        \"dialogue_id\": dialogue_id,\n",
    "                        \"metadata\": data[\"metadata\"],  \n",
    "                        \"broad_source\": broad_source,       \n",
    "                        \"collection\": collection,     \n",
    "                        \"domain\": domain,             \n",
    "                        \"title\": title,\n",
    "                        \"elicitors\": elicitor_list,  \n",
    "                        \"respondents\": respondent_list,           \n",
    "                        \"languages\": [\"en\"],\n",
    "                        \"turns\": []\n",
    "                    }\n",
    "                    counters[collection_id] += 1\n",
    "\n",
    "                    # Process turns\n",
    "                    turn_counter = 0\n",
    "                    for i, turn in enumerate(data[\"turns\"]):\n",
    "                        speaker = turn[\"speaker\"]\n",
    "\n",
    "                        # Determine the speaker's role\n",
    "                        role = \"other\"\n",
    "                        if speaker in elicitor_list:\n",
    "                            role = \"elicitor\"\n",
    "                        elif speaker in respondent_list:\n",
    "                            role = \"respondent\"\n",
    "\n",
    "                        # Check if this turn should be combined with the previous turn\n",
    "                        if i > 0 and turn[\"speaker\"] == new_data[\"turns\"][-1][\"speaker\"]:\n",
    "                            # Combine with the previous turn\n",
    "                            new_data[\"turns\"][-1][\"utterance\"] += \"\\n\\n\" + turn[\"utterance\"]\n",
    "                        else:\n",
    "                            # Add a new turn with an id at the top\n",
    "                            new_turn = {\n",
    "                                \"turn_id\": turn_counter,  # Counter at the top, renamed to 'id'\n",
    "                                \"timestamp\": turn[\"timestamp\"],\n",
    "                                \"speaker\": turn[\"speaker\"],\n",
    "                                \"role\": role,  # Assign the role based on the speaker\n",
    "                                \"utterance\": turn[\"utterance\"],\n",
    "                            }\n",
    "                            turn_counter += 1\n",
    "                            new_data[\"turns\"].append(new_turn)\n",
    "\n",
    "                # Write the modified JSON to the output location\n",
    "                with open(output_item_path, 'w', encoding='utf-8') as outfile:\n",
    "                    json.dump(new_data, outfile, indent=4, ensure_ascii=False)\n",
    "\n",
    "    # Initialize counters dictionary for tracking counts by collection\n",
    "    counters = {}\n",
    "\n",
    "    # Start processing from the root input directory\n",
    "    process_folder(input_dir, output_dir, counters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the JSON files\n",
    "process_json_files(input_directory, output_directory, folder_mapping)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yield_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
