{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Imports ----------------\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "from datetime import datetime\n",
    "from re import sub\n",
    "\n",
    "import yaml\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Config ----------------\n",
    "with open(\"../../../config/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "data_folder = os.path.join(config[\"paths\"][\"proj_store\"], \"data\")\n",
    "\n",
    "input_directory = f\"{data_folder}/raw_data/machine_collected/oyez_supreme_court/data/transcripts/\"\n",
    "output_base_directory = f\"{data_folder}/yield_v1_base/oyez_supreme_court/\"\n",
    "os.makedirs(output_base_directory, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers\n",
    "def snake_case(s):\n",
    "    return '_'.join(\n",
    "        sub('([A-Z][a-z]+)', r' \\1',\n",
    "        sub('([A-Z]+)', r' \\1',\n",
    "        s.replace('-', ' '))).split()).lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dialogue counter\n",
    "dialogue_counter = 1\n",
    "\n",
    "# Loop through all files in the input directory and subdirectories\n",
    "for root, _, files in os.walk(input_directory):\n",
    "    for file in files:\n",
    "        if file.endswith('.json'):\n",
    "            file_path = os.path.join(root, file)\n",
    "\n",
    "            # Load the original JSON file\n",
    "            with open(file_path, 'r') as f:\n",
    "                original_data = json.load(f)\n",
    "\n",
    "            # Extract year from the file path\n",
    "            year = root.split('/')[-1]\n",
    "            \n",
    "            \n",
    "            \n",
    "            transcript = original_data.get(\"transcript\")\n",
    "            \n",
    "            # Skip processing if 'transcript' is missing\n",
    "            if transcript is None:\n",
    "                #print(\"Skipping file as transcript is missing\")\n",
    "                continue  # Skip to the next file in the loop or exit this processing block\n",
    "            \n",
    "            \n",
    "            media_file = original_data.get(\"media_file\")\n",
    "            # Skip processing if 'media_file' is missing\n",
    "            if not media_file or all(item is None for item in media_file):\n",
    "                #print(\"Skipping file as transcript is missing\")\n",
    "                continue  # Skip to the next file in the loop or exit this processing block\n",
    "            audio_mpeg = media_file[0][\"href\"]\n",
    "            \n",
    "            id = original_data['id']\n",
    "            document_title = original_data[\"title\"].strip()\n",
    "            transcript_title = transcript.get(\"title\")\n",
    "            duration = transcript.get(\"duration\")\n",
    "            \n",
    "\n",
    "            #print(year)\n",
    "            # Prepare output directory path by year\n",
    "            output_directory = os.path.join(output_base_directory, year)\n",
    "            os.makedirs(output_directory, exist_ok=True)\n",
    "            \n",
    "            # Create filename without extension and generate output filename\n",
    "            filename_wo_ext = os.path.splitext(file)[0]\n",
    "            output_filename = '_'.join(filter(None, snake_case(f\"{filename_wo_ext}_{id}_{document_title}\").replace(\":\",\"\").split('_'))) + \".json\"\n",
    "\n",
    "\n",
    "            #print(output_filename)\n",
    "            \n",
    "            # Initialize elicitors and respondents for this file\n",
    "            elicitors_set = set()\n",
    "            respondents_set = set()\n",
    "\n",
    "            \n",
    "            #print(dialogue_counter)\n",
    "            #print(document_title)\n",
    "            # Transform the data to match the desired schema\n",
    "            transformed_data = {\n",
    "                \"dialogue_id\": f\"oyez-supreme-court-{dialogue_counter:05}\",\n",
    "                \"metadata\": {\n",
    "                    \"id\": id,\n",
    "                    \"document_title\": document_title,\n",
    "                    #\"transcript_title\": transcript_title,\n",
    "                    \"duration\": duration,\n",
    "                    \"links\": {\n",
    "                        \"audio_mpeg\": audio_mpeg,\n",
    "                        #\"audio_ogg\": original_data[\"media_file\"][1][\"href\"],\n",
    "                        #\"audio_hls\": original_data[\"media_file\"][2][\"href\"]\n",
    "                    },\n",
    "                    \"downloaded_on\": None\n",
    "                },\n",
    "                \"broad_source\": \"oyez_supreme_court\",\n",
    "                \"collection\": \"oyez_supreme_court\",\n",
    "                \"domain\": \"judicial_proceedings\",\n",
    "                \"title\": transcript_title,\n",
    "                \"elicitors\": [],\n",
    "                \"respondents\": [],\n",
    "                \"languages\": ['en'],\n",
    "                \"turns\": []\n",
    "            }\n",
    "\n",
    "            #print(transformed_data)\n",
    "\n",
    "            # Populate the turns array\n",
    "            turn_id = 1\n",
    "            for section in original_data[\"transcript\"][\"sections\"]:\n",
    "                for turn in section[\"turns\"]:\n",
    "                    # Check if the speaker field exists and is not null\n",
    "                    if not turn.get(\"speaker\"):\n",
    "                        continue  # Skip this turn if \"speaker\" is null\n",
    "\n",
    "                    # Extract speaker information\n",
    "                    speaker = turn[\"speaker\"][\"name\"]\n",
    "                    #speaker = None\n",
    "                    #print(speaker)\n",
    "                    #role = \"elicitor\" if turn[\"speaker\"][\"roles\"][0][\"type\"] == \"scotus_justice\" else \"respondent\"\n",
    "                    #role = None\n",
    "                    \n",
    "                    # Determine the role\n",
    "                    if \"roles\" in turn[\"speaker\"] and turn[\"speaker\"][\"roles\"]:\n",
    "                        role_type = turn[\"speaker\"][\"roles\"][0].get(\"type\")\n",
    "                        role = \"elicitor\" if role_type == \"scotus_justice\" else \"respondent\"\n",
    "                    else:\n",
    "                        role = \"respondent\"\n",
    "\n",
    "                    # Add speaker to elicitors or respondents set based on role\n",
    "                    if role == \"elicitor\":\n",
    "                        elicitors_set.add(speaker)\n",
    "                    elif role == \"respondent\":\n",
    "                        respondents_set.add(speaker)\n",
    "\n",
    "                    \n",
    "                    \n",
    "                   # Combine all text blocks into a single utterance\n",
    "                    combined_text = \"\\n\\n\".join([block[\"text\"] for block in turn[\"text_blocks\"]]).strip()\n",
    "                    \n",
    "                    # Format the start time as timestamp\n",
    "                    start_time = turn.get(\"start\")\n",
    "                    timestamp = f\"{int(start_time // 60):02}:{int(start_time % 60):02}:{int((start_time * 1000) % 1000):03}\"\n",
    "                    \n",
    "                    # Append the single entry with combined text to transformed_data\n",
    "                    transformed_data[\"turns\"].append({\n",
    "                        \"turn_id\": turn_id,\n",
    "                        \"timestamp\": timestamp,\n",
    "                        \"speaker\": speaker,                     \n",
    "                        \"role\": role,\n",
    "                        \"utterance\": combined_text,\n",
    "\n",
    "                    })\n",
    "                    turn_id += 1\n",
    "                    \n",
    "            # Convert sets to lists and assign to transformed_data\n",
    "            transformed_data[\"elicitors\"] = list(elicitors_set)\n",
    "            transformed_data[\"respondents\"] = list(respondents_set)\n",
    "\n",
    "\n",
    "            # Write transformed data to the output file in the specified directory\n",
    "            with open(os.path.join(output_directory, output_filename), 'w') as f:\n",
    "                json.dump(transformed_data, f, indent=4)\n",
    "\n",
    "            dialogue_counter += 1  # Increment dialogue counter\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yield_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
